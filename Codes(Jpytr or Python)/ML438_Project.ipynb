{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Classification using Transfer learning"
      ],
      "metadata": {
        "id": "_MnuQ5v60kyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ],
      "metadata": {
        "id": "262iO0lkTG-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJRKnt39kf3_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_mfcc_features(file_path, n_mfcc=13, sr=22050):\n",
        "    \"\"\"Extract 52 MFCC features (13 coefficients x 4 statistics)\"\"\"\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    mfcc_features = []\n",
        "    for i in range(n_mfcc):\n",
        "        mfcc_features.extend([\n",
        "            np.mean(mfccs[i]), np.std(mfccs[i]),\n",
        "            np.min(mfccs[i]), np.max(mfccs[i])\n",
        "        ])\n",
        "    return mfcc_features\n",
        "\n",
        "def extract_spectral_features(file_path, sr=22050):\n",
        "    \"\"\"Extract 8 spectral features\"\"\"\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
        "\n",
        "    return [\n",
        "        np.mean(spectral_centroids), np.std(spectral_centroids),\n",
        "        np.mean(spectral_rolloff), np.std(spectral_rolloff),\n",
        "        np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
        "        np.mean(zero_crossing_rate), np.std(zero_crossing_rate)\n",
        "    ]\n",
        "\n",
        "def extract_pitch_features(file_path, sr=22050):\n",
        "    \"\"\"Extract 4 pitch features\"\"\"\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
        "\n",
        "    f0 = []\n",
        "    for t in range(pitches.shape[1]):\n",
        "        index = magnitudes[:, t].argmax()\n",
        "        pitch = pitches[index, t]\n",
        "        if pitch > 0:\n",
        "            f0.append(pitch)\n",
        "\n",
        "    if len(f0) > 0:\n",
        "        return [np.mean(f0), np.std(f0), np.min(f0), np.max(f0)]\n",
        "    return [0, 0, 0, 0]\n",
        "\n",
        "def extract_all_features(audio_directory, output_file='all_speaker_features.csv'):\n",
        "    \"\"\"Extract all 64 features from audio files and save to CSV\"\"\"\n",
        "    wav_files = [os.path.join(audio_directory, f)\n",
        "                 for f in os.listdir(audio_directory)\n",
        "                 if f.lower().endswith('.wav')]\n",
        "\n",
        "    features_data = []\n",
        "    labels = []\n",
        "\n",
        "    mfcc_names = [f'mfcc_{i}_{stat}' for i in range(13)\n",
        "                  for stat in ['mean', 'std', 'min', 'max']]\n",
        "    spectral_names = ['spectral_centroid_mean', 'spectral_centroid_std',\n",
        "                      'spectral_rolloff_mean', 'spectral_rolloff_std',\n",
        "                      'spectral_bandwidth_mean', 'spectral_bandwidth_std',\n",
        "                      'zcr_mean', 'zcr_std']\n",
        "    pitch_names = ['pitch_mean', 'pitch_std', 'pitch_min', 'pitch_max']\n",
        "    feature_names = mfcc_names + spectral_names + pitch_names\n",
        "\n",
        "    for file_path in wav_files:\n",
        "        try:\n",
        "            all_features = (extract_mfcc_features(file_path) +\n",
        "                          extract_spectral_features(file_path) +\n",
        "                          extract_pitch_features(file_path))\n",
        "            features_data.append(all_features)\n",
        "            speaker = os.path.basename(file_path).split('-')[0]\n",
        "            labels.append(speaker)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {file_path}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(features_data, columns=feature_names)\n",
        "    df['speaker'] = labels\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Extracted {len(df)} samples, saved to {output_file}\")\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis & preprocessing"
      ],
      "metadata": {
        "id": "1IJF-UF-C8O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('all_speaker_features.csv')\n",
        "print(f\"Samples: {len(df)}, Features: {df.shape[1] - 1}\")\n",
        "print(df['speaker'].value_counts().sort_index())\n",
        "\n",
        "# Speaker distribution plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "counts = df['speaker'].value_counts().sort_index()\n",
        "colors = ['#e74c3c' if s in ['murad', 'teymur'] else '#3498db' for s in counts.index]\n",
        "plt.bar(counts.index, counts.values, color=colors)\n",
        "plt.xlabel('Speaker')\n",
        "plt.ylabel('Samples')\n",
        "plt.title('Speaker Distribution (Red = Brothers)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('speaker_distribution.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Scaling\n",
        "X = df.drop('speaker', axis=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Before/after scaling plots\n",
        "sample_features = ['mfcc_0_mean', 'mfcc_5_mean', 'spectral_centroid_mean',\n",
        "                   'spectral_rolloff_mean', 'zcr_mean', 'pitch_mean']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=X[sample_features])\n",
        "plt.title('BEFORE Scaling: Feature Ranges Differ Dramatically')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('before_scaling_boxplot.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=X_scaled[sample_features])\n",
        "plt.title('AFTER Scaling: All Features Centered Around 0')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('after_scaling_boxplot.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Correlation analysis\n",
        "corr_matrix = X_scaled.corr()\n",
        "\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "columns_to_remove = ['spectral_rolloff_mean', 'zcr_std']\n",
        "X_final = X_scaled.drop(columns=columns_to_remove)\n",
        "X_final['speaker'] = df['speaker'].values\n",
        "X_final.to_csv('features_processed.csv', index=False)\n",
        "print(f\"Final features: {X_final.shape[1] - 1}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "48Qb5Kp0vlpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train/Validation/Test Split"
      ],
      "metadata": {
        "id": "_szBiuAB7jYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('features_processed.csv')\n",
        "\n",
        "# Split brothers separately to ensure adequate test representation\n",
        "brothers = df[df['speaker'].isin(['murad', 'teymur'])].copy()\n",
        "diverse = df[~df['speaker'].isin(['murad', 'teymur'])].copy()\n",
        "\n",
        "brother_test_list, brother_val_list, brother_train_list = [], [], []\n",
        "\n",
        "for speaker in ['murad', 'teymur']:\n",
        "    speaker_data = brothers[brothers['speaker'] == speaker]\n",
        "    test_samples = speaker_data.sample(n=5, random_state=42)\n",
        "    remaining = speaker_data.drop(test_samples.index)\n",
        "    val_samples = remaining.sample(n=3, random_state=42)\n",
        "    train_samples = remaining.drop(val_samples.index)\n",
        "\n",
        "    brother_test_list.append(test_samples)\n",
        "    brother_val_list.append(val_samples)\n",
        "    brother_train_list.append(train_samples)\n",
        "\n",
        "brother_test = pd.concat(brother_test_list)\n",
        "brother_val = pd.concat(brother_val_list)\n",
        "brother_train = pd.concat(brother_train_list)\n",
        "\n",
        "# Stratified split for diverse speakers\n",
        "y_div = diverse['speaker']\n",
        "div_train, div_temp, _, y_div_temp = train_test_split(\n",
        "    diverse, y_div, test_size=0.3, random_state=42, stratify=y_div)\n",
        "div_val, div_test, _, _ = train_test_split(\n",
        "    div_temp, y_div_temp, test_size=0.5, random_state=42, stratify=y_div_temp)\n",
        "\n",
        "# Combine and shuffle\n",
        "train_df = pd.concat([brother_train, div_train]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "val_df = pd.concat([brother_val, div_val]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = pd.concat([brother_test, div_test]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "val_df.to_csv('val.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
      ],
      "metadata": {
        "id": "zIlX0ddz7nGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection - Lasso"
      ],
      "metadata": {
        "id": "IOTESihdVMXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "val_df = pd.read_csv('val.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "X_train = train_df.drop('speaker', axis=1)\n",
        "y_train = train_df['speaker']\n",
        "X_val = val_df.drop('speaker', axis=1)\n",
        "y_val = val_df['speaker']\n",
        "X_test = test_df.drop('speaker', axis=1)\n",
        "y_test = test_df['speaker']\n",
        "\n",
        "# Lasso feature selection with C=0.25\n",
        "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.25,\n",
        "                           random_state=42, max_iter=1000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Select features with non-zero coefficients\n",
        "selected_mask = np.any(lasso.coef_ != 0, axis=0)\n",
        "selected_features = X_train.columns[selected_mask].tolist()\n",
        "print(f\"Lasso selected {len(selected_features)} features\")\n",
        "\n",
        "# Save selected feature datasets\n",
        "train_selected = pd.concat([X_train[selected_features], y_train], axis=1)\n",
        "val_selected = pd.concat([X_val[selected_features], y_val], axis=1)\n",
        "test_selected = pd.concat([X_test[selected_features], y_test], axis=1)\n",
        "\n",
        "train_selected.to_csv('train_selected.csv', index=False)\n",
        "val_selected.to_csv('val_selected.csv', index=False)\n",
        "test_selected.to_csv('test_selected.csv', index=False)"
      ],
      "metadata": {
        "id": "R-Jy5j11UX0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature selection - correlation"
      ],
      "metadata": {
        "id": "MKDvIRzJVWxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col != 'speaker']\n",
        "X_train = train_df[feature_cols]\n",
        "\n",
        "# Compute F-scores\n",
        "f_scores, _ = f_classif(X_train, y_train)\n",
        "f_score_dict = dict(zip(feature_cols, f_scores))\n",
        "\n",
        "# Find and remove correlated features (|r| > 0.7)\n",
        "corr_matrix = X_train.corr().abs()\n",
        "THRESHOLD = 0.7\n",
        "features_to_remove = set()\n",
        "\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "for col in upper_tri.columns:\n",
        "    for idx in upper_tri.index:\n",
        "        corr_val = upper_tri.loc[idx, col]\n",
        "        if pd.notna(corr_val) and corr_val > THRESHOLD:\n",
        "            # Remove feature with lower F-score\n",
        "            if idx not in features_to_remove and col not in features_to_remove:\n",
        "                if f_score_dict[idx] >= f_score_dict[col]:\n",
        "                    features_to_remove.add(col)\n",
        "                else:\n",
        "                    features_to_remove.add(idx)\n",
        "\n",
        "selected_features_corr = [f for f in feature_cols if f not in features_to_remove]\n",
        "print(f\"Correlation-based: {len(selected_features_corr)} features\")\n",
        "\n",
        "# Save reduced datasets\n",
        "X_val = val_df[feature_cols]\n",
        "X_test = test_df[feature_cols]\n",
        "\n",
        "train_reduced = pd.concat([X_train[selected_features_corr], y_train], axis=1)\n",
        "val_reduced = pd.concat([X_val[selected_features_corr], y_val], axis=1)\n",
        "test_reduced = pd.concat([X_test[selected_features_corr], y_test], axis=1)\n",
        "\n",
        "train_reduced.to_csv('train_corr_reduced.csv', index=False)\n",
        "val_reduced.to_csv('val_corr_reduced.csv', index=False)\n",
        "test_reduced.to_csv('test_corr_reduced.csv', index=False)\n",
        "\n",
        "# Correlation comparison plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, ax=axes[0])\n",
        "axes[0].set_title(f'Before: {len(feature_cols)} Features')\n",
        "\n",
        "corr_reduced = X_train[selected_features_corr].corr().abs()\n",
        "sns.heatmap(corr_reduced, cmap='RdBu_r', center=0, ax=axes[1])\n",
        "axes[1].set_title(f'After: {len(selected_features_corr)} Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_reduction_heatmaps.png', dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "hsteSKc6Rj4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1 - Training"
      ],
      "metadata": {
        "id": "cgXah_5KK0Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import pickle\n",
        "\n",
        "train_df = pd.read_csv('train_selected.csv')\n",
        "val_df = pd.read_csv('val_selected.csv')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col != 'speaker']\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df['speaker']\n",
        "X_val = val_df[feature_cols]\n",
        "y_val = val_df['speaker']\n",
        "\n",
        "# Hyperparameter tuning\n",
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "results = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, penalty='l2', solver='lbfgs',\n",
        "                               max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    precision = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    results.append({'C': C, 'precision': precision, 'recall': recall, 'model': model})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "best_idx = ((results_df['precision'] + results_df['recall']) / 2).idxmax()\n",
        "best_model = results[best_idx]['model']\n",
        "print(f\"Best C: {results[best_idx]['C']}\")\n",
        "\n",
        "# Save model\n",
        "with open('logreg_best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "# Tuning plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.semilogx(results_df['C'], results_df['precision'], 'b-o', label='Precision')\n",
        "ax.semilogx(results_df['C'], results_df['recall'], 'r-s', label='Recall')\n",
        "ax.axvline(x=results[best_idx]['C'], color='green', linestyle=':', label=f\"Best C={results[best_idx]['C']}\")\n",
        "ax.set_xlabel('C')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title(f'Hyperparameter Tuning (L2, {len(feature_cols)} Lasso-selected features)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('logreg_tuning.png', dpi=150)\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "-no1bfY6bUYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2 - Training"
      ],
      "metadata": {
        "id": "G6EAnlZzf27s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train_corr_reduced.csv')\n",
        "val_df = pd.read_csv('val_corr_reduced.csv')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col != 'speaker']\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df['speaker']\n",
        "X_val = val_df[feature_cols]\n",
        "y_val = val_df['speaker']\n",
        "\n",
        "results = []\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, penalty='l2', solver='lbfgs',\n",
        "                               max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    precision = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    results.append({'C': C, 'precision': precision, 'recall': recall, 'model': model})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "best_idx = ((results_df['precision'] + results_df['recall']) / 2).idxmax()\n",
        "best_model_corr = results[best_idx]['model']\n",
        "print(f\"Best C: {results[best_idx]['C']}\")\n",
        "\n",
        "with open('logreg_corr_best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model_corr, f)\n",
        "\n",
        "# Tuning plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.semilogx(results_df['C'], results_df['precision'], 'b-o', label='Precision')\n",
        "ax.semilogx(results_df['C'], results_df['recall'], 'r-s', label='Recall')\n",
        "ax.axvline(x=results[best_idx]['C'], color='green', linestyle=':', label=f\"Best C={results[best_idx]['C']}\")\n",
        "ax.set_xlabel('C')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title(f'Hyperparameter Tuning (L2, {len(feature_cols)} Correlation-reduced features)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('logreg_corr_tuning.png', dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Zl2GFwWXbVIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning Curves"
      ],
      "metadata": {
        "id": "90UTW-QXh7it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_lasso = pd.read_csv('train_selected.csv')\n",
        "val_lasso = pd.read_csv('val_selected.csv')\n",
        "train_corr = pd.read_csv('train_corr_reduced.csv')\n",
        "val_corr = pd.read_csv('val_corr_reduced.csv')\n",
        "\n",
        "def compute_learning_curve(X_train, y_train, X_val, y_val, train_sizes, C=0.1):\n",
        "    results = {'train_size': [], 'train_prec': [], 'train_rec': [], 'val_prec': [], 'val_rec': []}\n",
        "    n_total = len(X_train)\n",
        "\n",
        "    for size_frac in train_sizes:\n",
        "        n_samples = int(size_frac * n_total)\n",
        "        X_sub, y_sub = X_train.iloc[:n_samples], y_train.iloc[:n_samples]\n",
        "\n",
        "        model = LogisticRegression(C=C, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "        model.fit(X_sub, y_sub)\n",
        "\n",
        "        y_train_pred = model.predict(X_sub)\n",
        "        y_val_pred = model.predict(X_val)\n",
        "\n",
        "        results['train_size'].append(n_samples)\n",
        "        results['train_prec'].append(precision_score(y_sub, y_train_pred, average='macro', zero_division=0))\n",
        "        results['train_rec'].append(recall_score(y_sub, y_train_pred, average='macro', zero_division=0))\n",
        "        results['val_prec'].append(precision_score(y_val, y_val_pred, average='macro', zero_division=0))\n",
        "        results['val_rec'].append(recall_score(y_val, y_val_pred, average='macro', zero_division=0))\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "feature_cols_lasso = [c for c in train_lasso.columns if c != 'speaker']\n",
        "feature_cols_corr = [c for c in train_corr.columns if c != 'speaker']\n",
        "\n",
        "lasso_curves = compute_learning_curve(\n",
        "    train_lasso[feature_cols_lasso], train_lasso['speaker'],\n",
        "    val_lasso[feature_cols_lasso], val_lasso['speaker'], train_sizes)\n",
        "\n",
        "corr_curves = compute_learning_curve(\n",
        "    train_corr[feature_cols_corr], train_corr['speaker'],\n",
        "    val_corr[feature_cols_corr], val_corr['speaker'], train_sizes)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "axes[0, 0].plot(lasso_curves['train_size'], lasso_curves['train_prec'], 'b-o', label='Train')\n",
        "axes[0, 0].plot(lasso_curves['train_size'], lasso_curves['val_prec'], 'r-s', label='Validation')\n",
        "axes[0, 0].set_title(f'Lasso Model ({len(feature_cols_lasso)} features) - Precision')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(lasso_curves['train_size'], lasso_curves['train_rec'], 'b-o', label='Train')\n",
        "axes[0, 1].plot(lasso_curves['train_size'], lasso_curves['val_rec'], 'r-s', label='Validation')\n",
        "axes[0, 1].set_title(f'Lasso Model ({len(feature_cols_lasso)} features) - Recall')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].plot(corr_curves['train_size'], corr_curves['train_prec'], 'b-o', label='Train')\n",
        "axes[1, 0].plot(corr_curves['train_size'], corr_curves['val_prec'], 'r-s', label='Validation')\n",
        "axes[1, 0].set_title(f'Correlation Model ({len(feature_cols_corr)} features) - Precision')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].plot(corr_curves['train_size'], corr_curves['train_rec'], 'b-o', label='Train')\n",
        "axes[1, 1].plot(corr_curves['train_size'], corr_curves['val_rec'], 'r-s', label='Validation')\n",
        "axes[1, 1].set_title(f'Correlation Model ({len(feature_cols_corr)} features) - Recall')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Learning Curves (C=0.1, L2 Regularization)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('learning_curves.png', dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "sFamg9WLgNgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluations"
      ],
      "metadata": {
        "id": "TeQREkJ5l_xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "# Load test data and models\n",
        "test_lasso = pd.read_csv('test_selected.csv')\n",
        "test_corr = pd.read_csv('test_corr_reduced.csv')\n",
        "\n",
        "feature_cols_lasso = [c for c in test_lasso.columns if c != 'speaker']\n",
        "feature_cols_corr = [c for c in test_corr.columns if c != 'speaker']\n",
        "\n",
        "X_test_lasso = test_lasso[feature_cols_lasso]\n",
        "X_test_corr = test_corr[feature_cols_corr]\n",
        "y_test = test_lasso['speaker']\n",
        "\n",
        "with open('logreg_best_model.pkl', 'rb') as f:\n",
        "    model_lasso = pickle.load(f)\n",
        "with open('logreg_corr_best_model.pkl', 'rb') as f:\n",
        "    model_corr = pickle.load(f)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lasso = model_lasso.predict(X_test_lasso)\n",
        "y_pred_corr = model_corr.predict(X_test_corr)\n",
        "y_prob_lasso = model_lasso.predict_proba(X_test_lasso)\n",
        "y_prob_corr = model_corr.predict_proba(X_test_corr)\n",
        "\n",
        "classes = sorted(y_test.unique())\n",
        "\n",
        "# Overall metrics\n",
        "print(\"Lasso Model:\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred_lasso, average='macro'):.4f}\")\n",
        "print(f\"  Recall: {recall_score(y_test, y_pred_lasso, average='macro'):.4f}\")\n",
        "print(\"\\nCorrelation Model:\")\n",
        "print(f\"  Precision: {precision_score(y_test, y_pred_corr, average='macro'):.4f}\")\n",
        "print(f\"  Recall: {recall_score(y_test, y_pred_corr, average='macro'):.4f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "for ax, y_pred, title in [(axes[0], y_pred_lasso, \"Lasso Model (43 features)\"),\n",
        "                           (axes[1], y_pred_corr, \"Correlation Model (29 features)\")]:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    # Highlight brothers\n",
        "    murad_idx, teymur_idx = classes.index('murad'), classes.index('teymur')\n",
        "    for idx in [murad_idx, teymur_idx]:\n",
        "        ax.add_patch(plt.Rectangle((0, idx), len(classes), 1, fill=False, edgecolor='red', linewidth=2))\n",
        "        ax.add_patch(plt.Rectangle((idx, 0), 1, len(classes), fill=False, edgecolor='red', linewidth=2))\n",
        "\n",
        "plt.suptitle('Confusion Matrices (Red boxes = Brother classes)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Brother analysis\n",
        "def analyze_brothers(y_true, y_pred, name):\n",
        "    murad_mask = y_true == 'murad'\n",
        "    teymur_mask = y_true == 'teymur'\n",
        "\n",
        "    murad_correct = (y_pred[murad_mask] == 'murad').sum()\n",
        "    murad_as_teymur = (y_pred[murad_mask] == 'teymur').sum()\n",
        "    teymur_correct = (y_pred[teymur_mask] == 'teymur').sum()\n",
        "    teymur_as_murad = (y_pred[teymur_mask] == 'murad').sum()\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Murad: {murad_correct}/{murad_mask.sum()} correct, {murad_as_teymur} as Teymur\")\n",
        "    print(f\"  Teymur: {teymur_correct}/{teymur_mask.sum()} correct, {teymur_as_murad} as Murad\")\n",
        "    print(f\"  Brother confusion: {murad_as_teymur + teymur_as_murad}\")\n",
        "\n",
        "analyze_brothers(y_test, y_pred_lasso, \"Lasso Model\")\n",
        "analyze_brothers(y_test, y_pred_corr, \"Correlation Model\")\n",
        "\n",
        "# ROC curves\n",
        "y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "for ax, y_prob, title in [(axes[0], y_prob_lasso, \"Lasso Model\"),\n",
        "                           (axes[1], y_prob_corr, \"Correlation Model\")]:\n",
        "    for i, class_name in enumerate(classes):\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        lw = 3 if class_name in ['murad', 'teymur'] else 1\n",
        "        label = f'{class_name} (AUC={roc_auc:.2f})' + (' ★' if class_name in ['murad', 'teymur'] else '')\n",
        "        ax.plot(fpr, tpr, linewidth=lw, label=label)\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title(title)\n",
        "    ax.legend(loc='lower right', fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('ROC Curves (★ = Brother classes)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curves.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Error analysis\n",
        "lasso_errors = set(np.where(y_pred_lasso != y_test.values)[0])\n",
        "corr_errors = set(np.where(y_pred_corr != y_test.values)[0])\n",
        "\n",
        "print(f\"\\nLasso errors: {len(lasso_errors)}\")\n",
        "print(f\"Correlation errors: {len(corr_errors)}\")\n",
        "\n",
        "for idx in corr_errors:\n",
        "    print(f\"  Sample {idx}: {y_test.iloc[idx]} → {y_pred_corr[idx]}\")\n",
        "\n",
        "# Venn diagram\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "circle1 = Circle((0.35, 0.5), 0.3, alpha=0.5, color='blue')\n",
        "circle2 = Circle((0.65, 0.5), 0.3, alpha=0.5, color='red')\n",
        "ax.add_patch(circle1)\n",
        "ax.add_patch(circle2)\n",
        "\n",
        "only_lasso = lasso_errors - corr_errors\n",
        "only_corr = corr_errors - lasso_errors\n",
        "both = lasso_errors & corr_errors\n",
        "\n",
        "ax.text(0.2, 0.5, str(len(only_lasso)), fontsize=24, ha='center', va='center', fontweight='bold')\n",
        "ax.text(0.5, 0.5, str(len(both)), fontsize=24, ha='center', va='center', fontweight='bold')\n",
        "ax.text(0.8, 0.5, str(len(only_corr)), fontsize=24, ha='center', va='center', fontweight='bold')\n",
        "ax.text(0.2, 0.15, 'Lasso only', fontsize=12, ha='center', color='blue')\n",
        "ax.text(0.8, 0.15, 'Correlation only', fontsize=12, ha='center', color='red')\n",
        "ax.text(0.5, 0.85, 'Both models', fontsize=12, ha='center')\n",
        "\n",
        "correct_both = len(y_test) - len(lasso_errors | corr_errors)\n",
        "ax.text(0.5, 0.05, f'Correctly classified by both: {correct_both}/{len(y_test)}', fontsize=12, ha='center')\n",
        "\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_aspect('equal')\n",
        "ax.axis('off')\n",
        "ax.set_title('Venn Diagram of Classification Errors')\n",
        "plt.savefig('error_venn_diagram.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nDone! All plots saved.\")"
      ],
      "metadata": {
        "id": "MSEolEzVh9zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eusd_9somA0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}